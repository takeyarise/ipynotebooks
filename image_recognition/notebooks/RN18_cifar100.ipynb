{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18 + CIFAR100 の性能確認\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Project Root Directory\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "root_marker = \"common\"\n",
    "while current_dir != os.path.dirname(current_dir):\n",
    "    if root_marker in os.listdir(current_dir):\n",
    "        break\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "project_root = current_dir\n",
    "if os.getcwd() != project_root:\n",
    "    %cd {project_root};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "import lightning as L\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from common.utils.training import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_phase(fabric):\n",
    "    L.seed_everything(seed=0xcafe, workers=True, verbose=True)\n",
    "    batch_size = 32\n",
    "    epochs = 300\n",
    "    print_interval = 10\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToImage(),\n",
    "        transforms.RandomResizedCrop(size=32, antialias=True),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    train_ds = datasets.CIFAR100(\n",
    "        root='./image_recognition/data',\n",
    "        train=True,\n",
    "        transform=train_transform,\n",
    "        download=True,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    n_data = len(train_ds)\n",
    "\n",
    "    net = resnet18(weights=None, num_classes=100)\n",
    "    optimizer = optim.RAdam(\n",
    "        params=net.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay=5e-4,\n",
    "        decoupled_weight_decay=True,\n",
    "        foreach=True,\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer=optimizer,\n",
    "        milestones=[100, 200],\n",
    "        gamma=0.1,\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = torch.compile(net, mode='reduce-overhead')\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "    loader = fabric.setup_dataloaders(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            fabric.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * len(x)\n",
    "\n",
    "        scheduler.step()\n",
    "        total_loss = total_loss / n_data\n",
    "        logs['loss'].append(total_loss)\n",
    "\n",
    "        if epoch == 0 or (epoch + 1) % print_interval == 0:\n",
    "            print(f\"EPOCH: {epoch + 1}/{epochs}, LOSS: {total_loss:.5f}\")\n",
    "\n",
    "    torch.save(net.to('cpu').state_dict(), './image_recognition/weights/CIFAR100_RN18.pth')\n",
    "    return dict(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "Seed set to 51966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd696cbf9824af98b5d330c74c8a572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/300, LOSS: 4.23593\n",
      "EPOCH: 10/300, LOSS: 2.91062\n",
      "EPOCH: 20/300, LOSS: 2.48746\n",
      "EPOCH: 30/300, LOSS: 2.24010\n",
      "EPOCH: 40/300, LOSS: 2.06269\n",
      "EPOCH: 50/300, LOSS: 1.92576\n",
      "EPOCH: 60/300, LOSS: 1.80724\n",
      "EPOCH: 70/300, LOSS: 1.70563\n",
      "EPOCH: 80/300, LOSS: 1.61176\n",
      "EPOCH: 90/300, LOSS: 1.52736\n",
      "EPOCH: 100/300, LOSS: 1.44388\n",
      "EPOCH: 110/300, LOSS: 1.21908\n",
      "EPOCH: 120/300, LOSS: 1.18727\n",
      "EPOCH: 130/300, LOSS: 1.16606\n",
      "EPOCH: 140/300, LOSS: 1.15199\n",
      "EPOCH: 150/300, LOSS: 1.12781\n",
      "EPOCH: 160/300, LOSS: 1.11832\n",
      "EPOCH: 170/300, LOSS: 1.09859\n",
      "EPOCH: 180/300, LOSS: 1.09236\n",
      "EPOCH: 190/300, LOSS: 1.08570\n",
      "EPOCH: 200/300, LOSS: 1.07308\n",
      "EPOCH: 210/300, LOSS: 1.05013\n",
      "EPOCH: 220/300, LOSS: 1.04341\n",
      "EPOCH: 230/300, LOSS: 1.05114\n",
      "EPOCH: 240/300, LOSS: 1.05063\n",
      "EPOCH: 250/300, LOSS: 1.03405\n",
      "EPOCH: 260/300, LOSS: 1.03838\n",
      "EPOCH: 270/300, LOSS: 1.03224\n",
      "EPOCH: 280/300, LOSS: 1.03460\n",
      "EPOCH: 290/300, LOSS: 1.02707\n",
      "EPOCH: 300/300, LOSS: 1.03347\n"
     ]
    }
   ],
   "source": [
    "fabric = L.Fabric(\n",
    "    accelerator='cuda',\n",
    "    devices=[0],\n",
    "    precision='bf16-mixed',\n",
    ")\n",
    "logs = fabric.launch(train_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_phase(weight_name, device):\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToImage(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    test_ds = datasets.CIFAR100(\n",
    "        root='./image_recognition/data',\n",
    "        train=False,\n",
    "        transform=test_transform,\n",
    "        download=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    n_data = len(test_ds)\n",
    "\n",
    "    net = resnet18(weights=None, num_classes=100).to(device)\n",
    "    net.load_state_dict(torch.load('./image_recognition/weights/' + weight_name, weights_only=True))\n",
    "\n",
    "    acc = evaluate(net, test_loader, device)\n",
    "    print(f'Acc: {os.path.splitext(weight_name)[0]}, {acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Acc: CIFAR100_RN18, 0.55480\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "evaluate_phase('CIFAR100_RN18.pth', device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
