{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeiT + CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Project Root Directory\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "root_marker = \"common\"\n",
    "while current_dir != os.path.dirname(current_dir):\n",
    "    if root_marker in os.listdir(current_dir):\n",
    "        break\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "project_root = current_dir\n",
    "if os.getcwd() != project_root:\n",
    "    %cd {project_root};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from timm.models import deit\n",
    "from timm.optim import Lookahead\n",
    "import lightning as L\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "from common.optim.ranger import Ranger\n",
    "from common.optim.sam import SAM, bypass_running_stats\n",
    "from common.utils.training import evaluate\n",
    "from common.loss.acls import ACLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list()\n",
    "results = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VisionTransformer                        [1, 100]                  12,672\n",
       "├─PatchEmbed: 1-1                        [1, 64, 192]              --\n",
       "│    └─Conv2d: 2-1                       [1, 192, 8, 8]            9,408\n",
       "│    └─Identity: 2-2                     [1, 64, 192]              --\n",
       "├─Dropout: 1-2                           [1, 65, 192]              --\n",
       "├─Identity: 1-3                          [1, 65, 192]              --\n",
       "├─Identity: 1-4                          [1, 65, 192]              --\n",
       "├─Sequential: 1-5                        [1, 65, 192]              --\n",
       "│    └─Block: 2-3                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-1               [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-2               [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-3                [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-4                [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-5               [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-6                     [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-7                [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-8                [1, 65, 192]              --\n",
       "│    └─Block: 2-4                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-9               [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-10              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-11               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-12               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-13              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-14                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-15               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-16               [1, 65, 192]              --\n",
       "│    └─Block: 2-5                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-17              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-18              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-19               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-20               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-21              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-22                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-23               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-24               [1, 65, 192]              --\n",
       "│    └─Block: 2-6                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-25              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-26              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-27               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-28               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-29              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-30                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-31               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-32               [1, 65, 192]              --\n",
       "│    └─Block: 2-7                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-33              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-34              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-35               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-36               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-37              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-38                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-39               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-40               [1, 65, 192]              --\n",
       "│    └─Block: 2-8                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-41              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-42              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-43               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-44               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-45              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-46                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-47               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-48               [1, 65, 192]              --\n",
       "│    └─Block: 2-9                        [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-49              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-50              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-51               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-52               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-53              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-54                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-55               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-56               [1, 65, 192]              --\n",
       "│    └─Block: 2-10                       [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-57              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-58              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-59               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-60               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-61              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-62                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-63               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-64               [1, 65, 192]              --\n",
       "│    └─Block: 2-11                       [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-65              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-66              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-67               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-68               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-69              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-70                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-71               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-72               [1, 65, 192]              --\n",
       "│    └─Block: 2-12                       [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-73              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-74              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-75               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-76               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-77              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-78                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-79               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-80               [1, 65, 192]              --\n",
       "│    └─Block: 2-13                       [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-81              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-82              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-83               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-84               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-85              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-86                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-87               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-88               [1, 65, 192]              --\n",
       "│    └─Block: 2-14                       [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-89              [1, 65, 192]              384\n",
       "│    │    └─Attention: 3-90              [1, 65, 192]              148,224\n",
       "│    │    └─Identity: 3-91               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-92               [1, 65, 192]              --\n",
       "│    │    └─LayerNorm: 3-93              [1, 65, 192]              384\n",
       "│    │    └─Mlp: 3-94                    [1, 65, 192]              295,872\n",
       "│    │    └─Identity: 3-95               [1, 65, 192]              --\n",
       "│    │    └─Identity: 3-96               [1, 65, 192]              --\n",
       "├─LayerNorm: 1-6                         [1, 65, 192]              384\n",
       "├─Identity: 1-7                          [1, 192]                  --\n",
       "├─Dropout: 1-8                           [1, 192]                  --\n",
       "├─Linear: 1-9                            [1, 100]                  19,300\n",
       "==========================================================================================\n",
       "Total params: 5,380,132\n",
       "Trainable params: 5,380,132\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 5.96\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 13.38\n",
       "Params size (MB): 21.47\n",
       "Estimated Total Size (MB): 34.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(deit.deit_tiny_patch16_224(num_classes=100, img_size=(32, 32), patch_size=(4, 4)), (1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RA + L, OCLR, LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar100_deit_tiny_ra_l_oclr_ls(fabric):\n",
    "    L.seed_everything(seed=0xcafe, workers=True, verbose=True)\n",
    "    batch_size = 32\n",
    "    epochs = 200\n",
    "    print_interval = 10\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToImage(),\n",
    "        transforms.RandomResizedCrop(size=32, antialias=True),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    train_ds = datasets.CIFAR100(\n",
    "        root='./image_recognition/data',\n",
    "        train=True,\n",
    "        transform=train_transform,\n",
    "        download=True,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    n_data = len(train_ds)\n",
    "\n",
    "    net = deit.deit_tiny_patch16_224(\n",
    "        num_classes=100,\n",
    "        img_size=(32, 32),\n",
    "        patch_size=(4, 4),\n",
    "    )\n",
    "    base_optimizer = optim.RAdam(\n",
    "        params=net.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay=5e-4,\n",
    "        decoupled_weight_decay=True,\n",
    "        foreach=True,\n",
    "    )\n",
    "    optimizer = Lookahead(\n",
    "        base_optimizer,\n",
    "        alpha=0.5,\n",
    "        k=6,\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=1e-3,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    model = torch.compile(net, mode='reduce-overhead')\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "    loader = fabric.setup_dataloaders(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            fabric.backward(loss)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item() * len(x)\n",
    "\n",
    "        total_loss = total_loss / n_data\n",
    "        logs['loss'].append(total_loss)\n",
    "\n",
    "        if epoch == 0 or (epoch + 1) % print_interval == 0:\n",
    "            print(f\"EPOCH: {epoch + 1}/{epochs}, LOSS: {total_loss:.5f}\")\n",
    "\n",
    "    torch.save(net.to('cpu').state_dict(), './image_recognition/weights/CIFAR100_DEIT_TINY_RA_L_OCLR_LS.pth')\n",
    "    return dict(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Seed set to 51966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe596b948f3493ba470b10a7caa9e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1011 10:55:17.152000 140455940327232 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] ps1 is not in var_ranges, defaulting to unknown range.\n",
      "W1011 10:55:18.853000 140455940327232 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] ps1 is not in var_ranges, defaulting to unknown range.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/200, LOSS: 4.35256\n",
      "EPOCH: 10/200, LOSS: 3.32435\n",
      "EPOCH: 20/200, LOSS: 2.88906\n",
      "EPOCH: 30/200, LOSS: 2.54611\n",
      "EPOCH: 40/200, LOSS: 2.22828\n",
      "EPOCH: 50/200, LOSS: 1.95240\n",
      "EPOCH: 60/200, LOSS: 1.72701\n",
      "EPOCH: 70/200, LOSS: 1.54929\n",
      "EPOCH: 80/200, LOSS: 1.43441\n",
      "EPOCH: 90/200, LOSS: 1.33232\n",
      "EPOCH: 100/200, LOSS: 1.25911\n",
      "EPOCH: 110/200, LOSS: 1.20714\n",
      "EPOCH: 120/200, LOSS: 1.15170\n",
      "EPOCH: 130/200, LOSS: 1.11554\n",
      "EPOCH: 140/200, LOSS: 1.07273\n",
      "EPOCH: 150/200, LOSS: 1.04279\n",
      "EPOCH: 160/200, LOSS: 1.01347\n",
      "EPOCH: 170/200, LOSS: 0.98418\n",
      "EPOCH: 180/200, LOSS: 0.97317\n",
      "EPOCH: 190/200, LOSS: 0.96284\n",
      "EPOCH: 200/200, LOSS: 0.96064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2655/3389566901.py:16: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  fig.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fabric = L.Fabric(\n",
    "    accelerator='cuda',\n",
    "    devices=[0],\n",
    "    precision='bf16-mixed',\n",
    ")\n",
    "name = 'CIFAR100_DEIT_TINY_RA_L_OCLR_LS'\n",
    "results[name] = fabric.launch(train_cifar100_deit_tiny_ra_l_oclr_ls)\n",
    "names.append(name)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 2))\n",
    "ax.plot(results[name]['loss'])\n",
    "ax.grid()\n",
    "ax.set_ylim((0.0, 4.0))\n",
    "ax.set_xlim((0, 200))\n",
    "fig.tight_layout()\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RA + L, OCLR, LS, FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar100_deit_tiny_ra_l_oclr_ls_ft(fabric):\n",
    "    L.seed_everything(seed=0xcafe, workers=True, verbose=True)\n",
    "    batch_size = 32\n",
    "    epochs = 200\n",
    "    print_interval = 10\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToImage(),\n",
    "        transforms.RandomResizedCrop(size=32, antialias=True),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    train_ds = datasets.CIFAR100(\n",
    "        root='./image_recognition/data',\n",
    "        train=True,\n",
    "        transform=train_transform,\n",
    "        download=True,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    n_data = len(train_ds)\n",
    "\n",
    "    net = deit.deit_tiny_patch16_224(\n",
    "        pretrained=True,\n",
    "        num_classes=100,\n",
    "        img_size=(32, 32),\n",
    "        patch_size=(4, 4),\n",
    "    )\n",
    "    base_optimizer = optim.RAdam(\n",
    "        params=net.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay=5e-4,\n",
    "        decoupled_weight_decay=True,\n",
    "        foreach=True,\n",
    "    )\n",
    "    optimizer = Lookahead(\n",
    "        base_optimizer,\n",
    "        alpha=0.5,\n",
    "        k=6,\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=1e-3,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    model = torch.compile(net, mode='reduce-overhead')\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "    loader = fabric.setup_dataloaders(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            fabric.backward(loss)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item() * len(x)\n",
    "\n",
    "        total_loss = total_loss / n_data\n",
    "        logs['loss'].append(total_loss)\n",
    "\n",
    "        if epoch == 0 or (epoch + 1) % print_interval == 0:\n",
    "            print(f\"EPOCH: {epoch + 1}/{epochs}, LOSS: {total_loss:.5f}\")\n",
    "\n",
    "    torch.save(net.to('cpu').state_dict(), './image_recognition/weights/CIFAR100_DEIT_TINY_RA_L_OCLR_LS_FT.pth')\n",
    "    return dict(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Seed set to 51966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93723789e04400fb6683e53b00d285c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574bde88ff5b421ca0e8ea75c03d199d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1011 12:21:13.898000 140066413393728 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] ps1 is not in var_ranges, defaulting to unknown range.\n",
      "W1011 12:21:15.559000 140066413393728 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] ps1 is not in var_ranges, defaulting to unknown range.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/200, LOSS: 3.97465\n",
      "EPOCH: 10/200, LOSS: 1.73952\n",
      "EPOCH: 20/200, LOSS: 1.66347\n",
      "EPOCH: 30/200, LOSS: 1.68526\n",
      "EPOCH: 40/200, LOSS: 1.67334\n",
      "EPOCH: 50/200, LOSS: 1.60221\n",
      "EPOCH: 60/200, LOSS: 1.49436\n",
      "EPOCH: 70/200, LOSS: 1.38542\n",
      "EPOCH: 80/200, LOSS: 1.31166\n",
      "EPOCH: 90/200, LOSS: 1.23854\n",
      "EPOCH: 100/200, LOSS: 1.18656\n",
      "EPOCH: 110/200, LOSS: 1.14670\n",
      "EPOCH: 120/200, LOSS: 1.10244\n",
      "EPOCH: 130/200, LOSS: 1.07118\n",
      "EPOCH: 140/200, LOSS: 1.04125\n",
      "EPOCH: 150/200, LOSS: 1.00694\n",
      "EPOCH: 160/200, LOSS: 0.98316\n",
      "EPOCH: 170/200, LOSS: 0.95497\n",
      "EPOCH: 180/200, LOSS: 0.94845\n",
      "EPOCH: 190/200, LOSS: 0.93549\n",
      "EPOCH: 200/200, LOSS: 0.93553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21148/3258549459.py:16: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  fig.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fabric = L.Fabric(\n",
    "    accelerator='cuda',\n",
    "    devices=[0],\n",
    "    precision='bf16-mixed',\n",
    ")\n",
    "name = 'CIFAR100_DEIT_TINY_RA_L_OCLR_LS_FT'\n",
    "results[name] = fabric.launch(train_cifar100_deit_tiny_ra_l_oclr_ls_ft)\n",
    "names.append(name)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 2))\n",
    "ax.plot(results[name]['loss'])\n",
    "ax.grid()\n",
    "ax.set_ylim((0.0, 4.0))\n",
    "ax.set_xlim((0, 200))\n",
    "fig.tight_layout()\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_phase(weight_name, device):\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToImage(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    test_ds = datasets.CIFAR100(\n",
    "        root='./image_recognition/data',\n",
    "        train=False,\n",
    "        transform=test_transform,\n",
    "        download=False,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    net = deit.deit_tiny_patch16_224(\n",
    "        num_classes=100,\n",
    "        img_size=(32, 32),\n",
    "        patch_size=(4, 4),\n",
    "    )\n",
    "    net.load_state_dict(torch.load('./image_recognition/weights/' + weight_name, weights_only=True))\n",
    "    net.to(device)\n",
    "\n",
    "    acc = evaluate(net, test_loader, device)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_ds = datasets.CIFAR100(\n",
    "    root='./image_recognition/data',\n",
    "    train=False,\n",
    "    download=True,\n",
    ")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIFAR100_DEIT_TINY_RA_L_OCLR_LS', 'CIFAR100_DEIT_TINY_RA_L_OCLR_LS_FT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search weights\n",
    "src = Path('./image_recognition/weights')\n",
    "src = src.glob('CIFAR100_DEIT_TINY*.pth')\n",
    "src = map(lambda p: p.stem, src)\n",
    "names = list(set(names) | set(src))\n",
    "del src\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: CIFAR100_DEIT_TINY_RA_L_OCLR_LS, 0.55850\n",
      "Acc: CIFAR100_DEIT_TINY_RA_L_OCLR_LS_FT, 0.75060\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    if not ('acc' in results[name]):\n",
    "        results[name]['acc'] = evaluate_phase(name + '.pth', device=device)\n",
    "    print(f'Acc: {name}, {results[name]['acc']:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynotebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
